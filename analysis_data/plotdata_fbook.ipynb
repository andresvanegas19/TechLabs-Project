{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This will show the scrapping into the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Into facebook and instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import facebook\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.facebook.com/'\n",
    "token = 'EAAI5xneADUoBAHxNkNeBacQ24C2QmygtkloTNMeqn0UZC87i2NWgwE9iiEsR0SlPsETXSobWN01beSdxrGQq6vtvtj3d6dZALS5oCD231xxZCn3ZCcpWBvz5bZAZCMAPmQvWXn9lMOYAv13uX5m0uTksghP3cHpUgZBIdpUbkj9tGzdRdw7ccJNuTKAab4umZB2NcynLiTfFepHgjVn4TZBVFHZC4AhZAFlNIAyldkhGweLRAZDZD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "graph = facebook.GraphAPI(token)\n",
    "profile = graph.get_object('me',fields='likes.limit(1000)')\n",
    "# {artists_we_like}\n",
    "fan_page = [profile['likes']['data'][num]['id'] for num in range(len(profile['likes']['data']))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With likes, get a sample of some those likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ It will dive into the facebook html to saw the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# This is for search into the html\n",
    "from bs4 import BeautifulSoup\n",
    "# This is for the regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_str(soup):\n",
    "    \"\"\"this function it will find the category of the page\"\"\"\n",
    "    for child in soup.findAll('div', re.compile(\"_4bl9\")):\n",
    "        # this will dive into subdiv and search the tag a\n",
    "        result = child.find_all('a', {'href': re.compile('(pages/category/*|/search/*)')})\n",
    "        if result:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mining_data(url):\n",
    "    \"\"\"This function is for mining data into the webpage\"\"\"\n",
    "    # take a request of the url and save into the variable soup\n",
    "    soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "    # Delete the tags and save into word\n",
    "    try:\n",
    "        soup = [word.text for word in found_str(soup)]\n",
    "    except:\n",
    "        soup = []\n",
    "    finally:\n",
    "        return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.5872118473053\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# get the sample of the fan_page\n",
    "MUESTRA = np.random.choice(fan_page, int(len(fan_page) / 98.2 * 25))\n",
    "\n",
    "fan_page_likes = [mining_data(URL + num) for num in MUESTRA]\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "# this show the time the operation took\n",
    "print(end - start)\n",
    "#sum(fan_page_likes, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Músico/banda',\n",
       " 'Hotel',\n",
       " 'Bar',\n",
       " 'Restaurante',\n",
       " 'Periódico',\n",
       " 'Medio de comunicación/noticias',\n",
       " 'Medio de comunicación/noticias',\n",
       " 'Sitio web',\n",
       " 'Bloguero',\n",
       " 'Creador de videos',\n",
       " 'Músico/banda',\n",
       " 'Hotel',\n",
       " 'Bar',\n",
       " 'Restaurante',\n",
       " 'Sitio web de entretenimiento',\n",
       " 'Videojuego',\n",
       " 'Interés',\n",
       " 'Emprendedor',\n",
       " 'Educación',\n",
       " 'Salud/belleza',\n",
       " 'Empresa de alimentos y bebidas',\n",
       " 'Medio de comunicación/noticias',\n",
       " 'Tienda de ropa',\n",
       " 'Medio de comunicación/noticias',\n",
       " 'Blog personal',\n",
       " 'Club de comedia',\n",
       " 'Blog personal',\n",
       " 'Salud/belleza',\n",
       " 'Ropa (marca)',\n",
       " 'Diseño y moda',\n",
       " 'Ropa (marca)',\n",
       " 'Medio de comunicación/noticias',\n",
       " 'Sitio web',\n",
       " 'Empresa']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "likes = list(chain.from_iterable(fan_page_likes))\n",
    "\n",
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
