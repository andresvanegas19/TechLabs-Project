{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This will show the scrapping into the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Into facebook and instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import facebook\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.facebook.com/'\n",
    "token = 'EAAI5xneADUoBAG5pyXdXTNdyZAyAwGKhMgxk8joXG1x4ZBJ6hNCU26cgeySLHDorJZBhaaE0wuJSCiCYeQwV8oZCzF1USTHfT6xEGk2ZBUuCPU5Y6U5vmUjEqXRdpAB8DulsDdradivslEv4qAZBjMTDeTTHI8SEjZCnAF9mLSnoivs0ePcnj7XxP6WsCyZARZCcZD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "graph = facebook.GraphAPI(token)\n",
    "profile = graph.get_object('me',fields='likes.limit(1000)')\n",
    "# {artists_we_like}\n",
    "fan_page = [profile['likes']['data'][num]['id'] for num in range(len(profile['likes']['data']))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With likes, get a sample of some those likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ It will dive into the facebook html to saw the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# This is for search into the html\n",
    "from bs4 import BeautifulSoup\n",
    "# This is for the regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_str(soup):\n",
    "    \"\"\"this function it will find the category of the page\"\"\"\n",
    "    for child in soup.findAll('div', re.compile(\"_4bl9\")):\n",
    "        # this will dive into subdiv and search the tag a\n",
    "        result = child.find_all('a', {'href': re.compile('(pages/category/*|/search/*)')})\n",
    "        if result:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mining_data(url):\n",
    "    \"\"\"This function is for mining data into the webpage\"\"\"\n",
    "    # take a request of the url and save into the variable soup\n",
    "    soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "    # Delete the tags and save into word\n",
    "    try:\n",
    "        soup = [word.text for word in found_str(soup)]\n",
    "    except:\n",
    "        soup = []\n",
    "    finally:\n",
    "        return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.642744064331055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# get the sample of the fan_page\n",
    "MUESTRA = np.random.choice(fan_page, int(len(fan_page) / 98.2 * 25))\n",
    "\n",
    "fan_page_likes = [mining_data(URL + num) for num in MUESTRA]\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "# this show the time the operation took\n",
    "print(end - start)\n",
    "#sum(fan_page_likes, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Músico/banda',\n",
       " 'Emprendedor',\n",
       " 'Educación',\n",
       " 'Salud/belleza',\n",
       " 'Videojuego',\n",
       " 'Videojuego',\n",
       " 'Blog personal',\n",
       " 'Medio de comunicación/noticias',\n",
       " 'Sitio web',\n",
       " 'Músico/banda',\n",
       " 'Programa de TV',\n",
       " 'Película',\n",
       " 'Músico/banda',\n",
       " 'Película',\n",
       " 'Sitio web de noticias y medios de comunicación',\n",
       " 'Figura pública',\n",
       " 'Blog personal',\n",
       " 'Empresa',\n",
       " 'Diversión',\n",
       " 'Arte',\n",
       " 'Club de comedia',\n",
       " 'Músico/banda',\n",
       " 'Producto/servicio',\n",
       " 'Blog personal',\n",
       " 'Club de comedia']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "likes = list(chain.from_iterable(fan_page_likes))\n",
    "\n",
    "likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above array you will see in general the category of the pages that he follows.\n",
    "This data is a sample of 20 pages in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
